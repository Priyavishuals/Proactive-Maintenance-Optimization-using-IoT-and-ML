{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1 - Regression (RUL) using Autoencoder + Kalman + LSTM\n",
    "\n",
    "Here, we fit an autoencoder on the train set which learns to regenerate the train set. By using the activations of some intermediate layer of the autoencoder, we get an efficient representation of the original noisy train data. This representation of the original data can be used to train the LSTM model for predicting RUL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting seed for reproducability\n",
    "np.random.seed(1234)  \n",
    "PYTHONHASHSEED = 0\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Train and Test Data using Kalman Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training data \n",
    "train_df = pd.read_csv('data/train_01.txt', sep=\" \", header=None)\n",
    "train_df.drop(train_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "train_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5   ...        s12      s13      s14     s15   s16  s17   s18    s19  \\\n",
       "0  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n",
       "1  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n",
       "2  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n",
       "3  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n",
       "4  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n",
       "\n",
       "     s20      s21  \n",
       "0  39.06  23.4190  \n",
       "1  39.00  23.4236  \n",
       "2  38.95  23.3442  \n",
       "3  38.88  23.3739  \n",
       "4  38.90  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns\n",
    "cols = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "       's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "       's15', 's16', 's17', 's18', 's19', 's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'setting1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in train_df.columns:\n",
    "    if cols == 'id':\n",
    "        continue;\n",
    "    if cols == 'cycle':\n",
    "        continue;\n",
    "    else:\n",
    "        print(cols)\n",
    "        kf = KalmanFilter(transition_matrices = [1],\n",
    "                      observation_matrices = [1],\n",
    "                      initial_state_mean = train_df[cols].values[0],\n",
    "                      initial_state_covariance = 1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=.01)\n",
    "        state_means,_ = kf.filter(train_df[cols].values)\n",
    "        train_df[cols] = state_means.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read test data\n",
    "test_df = pd.read_csv('dataset1/PM_test_01.txt', sep=\" \", header=None)\n",
    "test_df.drop(test_df.columns[[26, 27]], axis=1, inplace=True)\n",
    "test_df.columns = ['id', 'cycle', 'setting1', 'setting2', 'setting3', 's1', 's2', 's3',\n",
    "                     's4', 's5', 's6', 's7', 's8', 's9', 's10', 's11', 's12', 's13', 's14',\n",
    "                     's15', 's16', 's17', 's18', 's19', 's20', 's21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting1\n",
      "setting2\n",
      "setting3\n",
      "s1\n",
      "s2\n",
      "s3\n",
      "s4\n",
      "s5\n",
      "s6\n",
      "s7\n",
      "s8\n",
      "s9\n",
      "s10\n",
      "s11\n",
      "s12\n",
      "s13\n",
      "s14\n",
      "s15\n",
      "s16\n",
      "s17\n",
      "s18\n",
      "s19\n",
      "s20\n",
      "s21\n"
     ]
    }
   ],
   "source": [
    "for cols in test_df.columns:\n",
    "    if cols == 'id':\n",
    "        continue;\n",
    "    if cols == 'cycle':\n",
    "        continue;\n",
    "    else:\n",
    "        print(cols)\n",
    "        kf = KalmanFilter(transition_matrices = [1],\n",
    "                      observation_matrices = [1],\n",
    "                      initial_state_mean = test_df[cols].values[0],\n",
    "                      initial_state_covariance = 1,\n",
    "                      observation_covariance=1,\n",
    "                      transition_covariance=.01)\n",
    "        state_means,_ = kf.filter(test_df[cols].values)\n",
    "        test_df[cols] = state_means.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read ground truth data\n",
    "truth_df = pd.read_csv('data/truth_01.txt', sep=\" \", header=None)\n",
    "truth_df.drop(truth_df.columns[[1]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s12</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5   ...        s12      s13      s14     s15   s16  s17   s18    s19  \\\n",
       "0  14.62   ...     521.66  2388.02  8138.62  8.4195  0.03  392  2388  100.0   \n",
       "1  14.62   ...     522.28  2388.07  8131.49  8.4318  0.03  392  2388  100.0   \n",
       "2  14.62   ...     522.42  2388.03  8133.23  8.4178  0.03  390  2388  100.0   \n",
       "3  14.62   ...     522.86  2388.08  8133.83  8.3682  0.03  392  2388  100.0   \n",
       "4  14.62   ...     522.19  2388.04  8133.80  8.4294  0.03  393  2388  100.0   \n",
       "\n",
       "     s20      s21  \n",
       "0  39.06  23.4190  \n",
       "1  39.00  23.4236  \n",
       "2  38.95  23.3442  \n",
       "3  38.88  23.3739  \n",
       "4  38.90  23.4044  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df.sort_values(['id','cycle'])\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate True Labels (RUL) for Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5 ...       s13      s14     s15   s16  s17   s18    s19    s20  \\\n",
       "0  14.62 ...   2388.02  8138.62  8.4195  0.03  392  2388  100.0  39.06   \n",
       "1  14.62 ...   2388.07  8131.49  8.4318  0.03  392  2388  100.0  39.00   \n",
       "2  14.62 ...   2388.03  8133.23  8.4178  0.03  390  2388  100.0  38.95   \n",
       "3  14.62 ...   2388.08  8133.83  8.3682  0.03  392  2388  100.0  38.88   \n",
       "4  14.62 ...   2388.04  8133.80  8.4294  0.03  393  2388  100.0  38.90   \n",
       "\n",
       "       s21  RUL  \n",
       "0  23.4190  191  \n",
       "1  23.4236  190  \n",
       "2  23.3442  189  \n",
       "3  23.3739  188  \n",
       "4  23.4044  187  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Labeling - generate column RUL\n",
    "rul = pd.DataFrame(train_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "train_df = train_df.merge(rul, on=['id'], how='left')\n",
    "train_df['RUL'] = train_df['max'] - train_df['cycle']\n",
    "train_df.drop('max', axis=1, inplace=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>...</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3      s1      s2       s3       s4  \\\n",
       "0   1      1   -0.0007   -0.0004     100.0  518.67  641.82  1589.70  1400.60   \n",
       "1   1      2    0.0019   -0.0003     100.0  518.67  642.15  1591.82  1403.14   \n",
       "2   1      3   -0.0043    0.0003     100.0  518.67  642.35  1587.99  1404.20   \n",
       "3   1      4    0.0007    0.0000     100.0  518.67  642.35  1582.79  1401.87   \n",
       "4   1      5   -0.0019   -0.0002     100.0  518.67  642.37  1582.85  1406.22   \n",
       "\n",
       "      s5   ...       s15   s16  s17   s18    s19    s20      s21  RUL  label1  \\\n",
       "0  14.62   ...    8.4195  0.03  392  2388  100.0  39.06  23.4190  191       0   \n",
       "1  14.62   ...    8.4318  0.03  392  2388  100.0  39.00  23.4236  190       0   \n",
       "2  14.62   ...    8.4178  0.03  390  2388  100.0  38.95  23.3442  189       0   \n",
       "3  14.62   ...    8.3682  0.03  392  2388  100.0  38.88  23.3739  188       0   \n",
       "4  14.62   ...    8.4294  0.03  393  2388  100.0  38.90  23.4044  187       0   \n",
       "\n",
       "   label2  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate label columns for training data\n",
    "w1 = 30\n",
    "w0 = 15\n",
    "train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "train_df['label2'] = train_df['label1']\n",
    "train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.459770</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183735</td>\n",
       "      <td>0.406802</td>\n",
       "      <td>0.309757</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.724662</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283133</td>\n",
       "      <td>0.453019</td>\n",
       "      <td>0.352633</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.731014</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.252874</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.369523</td>\n",
       "      <td>0.370527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.627907</td>\n",
       "      <td>0.621375</td>\n",
       "      <td>189</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.343373</td>\n",
       "      <td>0.256159</td>\n",
       "      <td>0.331195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.662386</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.390805</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.257467</td>\n",
       "      <td>0.404625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.589147</td>\n",
       "      <td>0.704502</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.01108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.459770  0.166667       0.0  0.0  0.183735  0.406802  0.309757   \n",
       "1   1      2  0.609195  0.250000       0.0  0.0  0.283133  0.453019  0.352633   \n",
       "2   1      3  0.252874  0.750000       0.0  0.0  0.343373  0.369523  0.370527   \n",
       "3   1      4  0.540230  0.500000       0.0  0.0  0.343373  0.256159  0.331195   \n",
       "4   1      5  0.390805  0.333333       0.0  0.0  0.349398  0.257467  0.404625   \n",
       "\n",
       "    s5     ...      s16       s17  s18  s19       s20       s21  RUL  label1  \\\n",
       "0  0.0     ...      0.0  0.333333  0.0  0.0  0.713178  0.724662  191       0   \n",
       "1  0.0     ...      0.0  0.333333  0.0  0.0  0.666667  0.731014  190       0   \n",
       "2  0.0     ...      0.0  0.166667  0.0  0.0  0.627907  0.621375  189       0   \n",
       "3  0.0     ...      0.0  0.333333  0.0  0.0  0.573643  0.662386  188       0   \n",
       "4  0.0     ...      0.0  0.416667  0.0  0.0  0.589147  0.704502  187       0   \n",
       "\n",
       "   label2  cycle_norm  \n",
       "0       0     0.00000  \n",
       "1       0     0.00277  \n",
       "2       0     0.00554  \n",
       "3       0     0.00831  \n",
       "4       0     0.01108  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MinMax normalization\n",
    "train_df['cycle_norm'] = train_df['cycle']\n",
    "cols_normalize = train_df.columns.difference(['id','cycle','RUL','label1','label2'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s13</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "    s5     ...           s13       s14       s15  s16       s17  s18  s19  \\\n",
       "0  0.0     ...      0.220588  0.132160  0.308965  0.0  0.333333  0.0  0.0   \n",
       "1  0.0     ...      0.264706  0.204768  0.213159  0.0  0.416667  0.0  0.0   \n",
       "2  0.0     ...      0.220588  0.155640  0.458638  0.0  0.416667  0.0  0.0   \n",
       "3  0.0     ...      0.250000  0.170090  0.257022  0.0  0.250000  0.0  0.0   \n",
       "4  0.0     ...      0.220588  0.152751  0.300885  0.0  0.166667  0.0  0.0   \n",
       "\n",
       "        s20       s21  cycle_norm  \n",
       "0  0.558140  0.661834     0.00000  \n",
       "1  0.682171  0.686827     0.00277  \n",
       "2  0.728682  0.721348     0.00554  \n",
       "3  0.666667  0.662110     0.00831  \n",
       "4  0.658915  0.716377     0.01108  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['cycle_norm'] = test_df['cycle']\n",
    "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_df[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=test_df.index)\n",
    "test_join_df = test_df[test_df.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_df = test_join_df.reindex(columns = test_df.columns)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate True Labels (RUL) for Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate column max for test data\n",
    "rul = pd.DataFrame(test_df.groupby('id')['cycle'].max()).reset_index()\n",
    "rul.columns = ['id', 'max']\n",
    "truth_df.columns = ['more']\n",
    "truth_df['id'] = truth_df.index + 1\n",
    "truth_df['max'] = rul['max'] + truth_df['more']\n",
    "truth_df.drop('more', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s14</th>\n",
       "      <th>s15</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "    s5 ...        s14       s15  s16       s17  s18  s19       s20       s21  \\\n",
       "0  0.0 ...   0.132160  0.308965  0.0  0.333333  0.0  0.0  0.558140  0.661834   \n",
       "1  0.0 ...   0.204768  0.213159  0.0  0.416667  0.0  0.0  0.682171  0.686827   \n",
       "2  0.0 ...   0.155640  0.458638  0.0  0.416667  0.0  0.0  0.728682  0.721348   \n",
       "3  0.0 ...   0.170090  0.257022  0.0  0.250000  0.0  0.0  0.666667  0.662110   \n",
       "4  0.0 ...   0.152751  0.300885  0.0  0.166667  0.0  0.0  0.658915  0.716377   \n",
       "\n",
       "   cycle_norm  RUL  \n",
       "0     0.00000  142  \n",
       "1     0.00277  141  \n",
       "2     0.00554  140  \n",
       "3     0.00831  139  \n",
       "4     0.01108  138  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate RUL for test data\n",
    "test_df = test_df.merge(truth_df, on=['id'], how='left')\n",
    "test_df['RUL'] = test_df['max'] - test_df['cycle']\n",
    "test_df.drop('max', axis=1, inplace=True)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cycle</th>\n",
       "      <th>setting1</th>\n",
       "      <th>setting2</th>\n",
       "      <th>setting3</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>...</th>\n",
       "      <th>s16</th>\n",
       "      <th>s17</th>\n",
       "      <th>s18</th>\n",
       "      <th>s19</th>\n",
       "      <th>s20</th>\n",
       "      <th>s21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "      <th>label1</th>\n",
       "      <th>label2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.00277</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.01108</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  cycle  setting1  setting2  setting3   s1        s2        s3        s4  \\\n",
       "0   1      1  0.632184  0.750000       0.0  0.0  0.545181  0.310661  0.269413   \n",
       "1   1      2  0.344828  0.250000       0.0  0.0  0.150602  0.379551  0.222316   \n",
       "2   1      3  0.517241  0.583333       0.0  0.0  0.376506  0.346632  0.322248   \n",
       "3   1      4  0.741379  0.500000       0.0  0.0  0.370482  0.285154  0.408001   \n",
       "4   1      5  0.580460  0.500000       0.0  0.0  0.391566  0.352082  0.332039   \n",
       "\n",
       "    s5   ...    s16       s17  s18  s19       s20       s21  cycle_norm  RUL  \\\n",
       "0  0.0   ...    0.0  0.333333  0.0  0.0  0.558140  0.661834     0.00000  142   \n",
       "1  0.0   ...    0.0  0.416667  0.0  0.0  0.682171  0.686827     0.00277  141   \n",
       "2  0.0   ...    0.0  0.416667  0.0  0.0  0.728682  0.721348     0.00554  140   \n",
       "3  0.0   ...    0.0  0.250000  0.0  0.0  0.666667  0.662110     0.00831  139   \n",
       "4  0.0   ...    0.0  0.166667  0.0  0.0  0.658915  0.716377     0.01108  138   \n",
       "\n",
       "   label1  label2  \n",
       "0       0       0  \n",
       "1       0       0  \n",
       "2       0       0  \n",
       "3       0       0  \n",
       "4       0       0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate label columns w0 and w1 for test data\n",
    "test_df['label1'] = np.where(test_df['RUL'] <= w1, 1, 0 )\n",
    "test_df['label2'] = test_df['label1']\n",
    "test_df.loc[test_df['RUL'] <= w0, 'label2'] = 2\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['label1','label2'],axis=1,inplace=True)\n",
    "test_df.drop(['label1','label2'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['setting1', 'setting2', 'setting3', 's1', 's2', 's3', 's4', 's5', 's6', 's7', 's8', 's9', 's10', \n",
    "        's11', 's12', 's13', 's14', 's15', 's16', 's17', 's18', 's19', 's20', 's21', 'cycle_norm']\n",
    "len(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras import Model\n",
    "from keras import regularizers, optimizers, activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(cols)\n",
    "encoding_dim = 14\n",
    "\n",
    "input_layer = Input(shape=(input_dim, ))\n",
    "\n",
    "encoder = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
    "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
    "\n",
    "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
    "decoder = Dense(input_dim, activation='relu')(decoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33727, 25)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([train_df[cols], test_df[cols]])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 28667 samples, validate on 5060 samples\n",
      "Epoch 1/100\n",
      "28667/28667 [==============================] - 3s 98us/step - loss: 0.0463 - acc: 0.9742 - mean_squared_error: 0.0405 - val_loss: 0.0346 - val_acc: 0.9759 - val_mean_squared_error: 0.0323\n",
      "Epoch 2/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0302 - acc: 0.9765 - mean_squared_error: 0.0282 - val_loss: 0.0264 - val_acc: 0.9777 - val_mean_squared_error: 0.0250\n",
      "Epoch 3/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0271 - acc: 0.9837 - mean_squared_error: 0.0259 - val_loss: 0.0257 - val_acc: 0.9864 - val_mean_squared_error: 0.0248\n",
      "Epoch 4/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0265 - acc: 0.9854 - mean_squared_error: 0.0256 - val_loss: 0.0252 - val_acc: 0.9870 - val_mean_squared_error: 0.0245\n",
      "Epoch 5/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0259 - acc: 0.9853 - mean_squared_error: 0.0253 - val_loss: 0.0248 - val_acc: 0.9864 - val_mean_squared_error: 0.0243\n",
      "Epoch 6/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0256 - acc: 0.9859 - mean_squared_error: 0.0250 - val_loss: 0.0245 - val_acc: 0.9875 - val_mean_squared_error: 0.0240\n",
      "Epoch 7/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0237 - acc: 0.9856 - mean_squared_error: 0.0233 - val_loss: 0.0221 - val_acc: 0.9875 - val_mean_squared_error: 0.0217\n",
      "Epoch 8/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0224 - acc: 0.9848 - mean_squared_error: 0.0220 - val_loss: 0.0171 - val_acc: 0.9881 - val_mean_squared_error: 0.0167\n",
      "Epoch 9/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0074 - acc: 0.9811 - mean_squared_error: 0.0071 - val_loss: 0.0025 - val_acc: 0.9864 - val_mean_squared_error: 0.0022\n",
      "Epoch 10/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0025 - acc: 0.9852 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_acc: 0.9881 - val_mean_squared_error: 0.0021\n",
      "Epoch 11/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0024 - acc: 0.9847 - mean_squared_error: 0.0021 - val_loss: 0.0023 - val_acc: 0.9881 - val_mean_squared_error: 0.0020\n",
      "Epoch 12/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0024 - acc: 0.9848 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_acc: 0.9877 - val_mean_squared_error: 0.0020\n",
      "Epoch 13/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0023 - acc: 0.9850 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.9881 - val_mean_squared_error: 0.0020\n",
      "Epoch 14/100\n",
      "28667/28667 [==============================] - 2s 55us/step - loss: 0.0022 - acc: 0.9850 - mean_squared_error: 0.0020 - val_loss: 0.0022 - val_acc: 0.9885 - val_mean_squared_error: 0.0019\n",
      "Epoch 15/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0022 - acc: 0.9851 - mean_squared_error: 0.0020 - val_loss: 0.0021 - val_acc: 0.9885 - val_mean_squared_error: 0.0019\n",
      "Epoch 16/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0022 - acc: 0.9855 - mean_squared_error: 0.0019 - val_loss: 0.0021 - val_acc: 0.9881 - val_mean_squared_error: 0.0019\n",
      "Epoch 17/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0021 - acc: 0.9850 - mean_squared_error: 0.0019 - val_loss: 0.0020 - val_acc: 0.9895 - val_mean_squared_error: 0.0018\n",
      "Epoch 18/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0021 - acc: 0.9854 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_acc: 0.9885 - val_mean_squared_error: 0.0018\n",
      "Epoch 19/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0020 - acc: 0.9853 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.9891 - val_mean_squared_error: 0.0018\n",
      "Epoch 20/100\n",
      "28667/28667 [==============================] - 2s 53us/step - loss: 0.0020 - acc: 0.9852 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 21/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0020 - acc: 0.9851 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9874 - val_mean_squared_error: 0.0017\n",
      "Epoch 22/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0020 - acc: 0.9856 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9885 - val_mean_squared_error: 0.0017\n",
      "Epoch 23/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0020 - acc: 0.9860 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9897 - val_mean_squared_error: 0.0017\n",
      "Epoch 24/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9857 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9883 - val_mean_squared_error: 0.0018\n",
      "Epoch 25/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9856 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9870 - val_mean_squared_error: 0.0017\n",
      "Epoch 26/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9897 - val_mean_squared_error: 0.0017\n",
      "Epoch 27/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9853 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9868 - val_mean_squared_error: 0.0017\n",
      "Epoch 28/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 29/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9874 - val_mean_squared_error: 0.0017\n",
      "Epoch 30/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9903 - val_mean_squared_error: 0.0018\n",
      "Epoch 31/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9879 - val_mean_squared_error: 0.0017\n",
      "Epoch 32/100\n",
      "28667/28667 [==============================] - 2s 53us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9881 - val_mean_squared_error: 0.0017\n",
      "Epoch 33/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9866 - val_mean_squared_error: 0.0017\n",
      "Epoch 34/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 35/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9899 - val_mean_squared_error: 0.0017\n",
      "Epoch 36/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 37/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9856 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9885 - val_mean_squared_error: 0.0017\n",
      "Epoch 38/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9893 - val_mean_squared_error: 0.0017\n",
      "Epoch 39/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 40/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9887 - val_mean_squared_error: 0.0017\n",
      "Epoch 41/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9868 - val_mean_squared_error: 0.0018\n",
      "Epoch 42/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9891 - val_mean_squared_error: 0.0017\n",
      "Epoch 43/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9856 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9897 - val_mean_squared_error: 0.0017\n",
      "Epoch 44/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9889 - val_mean_squared_error: 0.0017\n",
      "Epoch 45/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9862 - val_mean_squared_error: 0.0017\n",
      "Epoch 46/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 47/100\n",
      "28667/28667 [==============================] - 1s 45us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9903 - val_mean_squared_error: 0.0018\n",
      "Epoch 48/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9875 - val_mean_squared_error: 0.0017\n",
      "Epoch 49/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9857 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9883 - val_mean_squared_error: 0.0017\n",
      "Epoch 50/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9879 - val_mean_squared_error: 0.0017\n",
      "Epoch 51/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9891 - val_mean_squared_error: 0.0017\n",
      "Epoch 52/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9893 - val_mean_squared_error: 0.0017\n",
      "Epoch 53/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 54/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9893 - val_mean_squared_error: 0.0017\n",
      "Epoch 55/100\n",
      "28667/28667 [==============================] - 2s 53us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9864 - val_mean_squared_error: 0.0017\n",
      "Epoch 56/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_acc: 0.9893 - val_mean_squared_error: 0.0017\n",
      "Epoch 57/100\n",
      "28667/28667 [==============================] - 2s 52us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 58/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0032 - val_acc: 0.9881 - val_mean_squared_error: 0.0030\n",
      "Epoch 59/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9885 - val_mean_squared_error: 0.0017\n",
      "Epoch 60/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9887 - val_mean_squared_error: 0.0017\n",
      "Epoch 61/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9872 - val_mean_squared_error: 0.0017\n",
      "Epoch 62/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 63/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9872 - val_mean_squared_error: 0.0017\n",
      "Epoch 64/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0018 - val_loss: 0.0019 - val_acc: 0.9885 - val_mean_squared_error: 0.0017\n",
      "Epoch 65/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9864 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9899 - val_mean_squared_error: 0.0017\n",
      "Epoch 66/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9870 - val_mean_squared_error: 0.0017\n",
      "Epoch 67/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9874 - val_mean_squared_error: 0.0017\n",
      "Epoch 68/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9868 - val_mean_squared_error: 0.0017\n",
      "Epoch 69/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 70/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 71/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9866 - val_mean_squared_error: 0.0017\n",
      "Epoch 72/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 73/100\n",
      "28667/28667 [==============================] - 2s 57us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9887 - val_mean_squared_error: 0.0017\n",
      "Epoch 74/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9885 - val_mean_squared_error: 0.0017\n",
      "Epoch 75/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0018 - val_loss: 0.0020 - val_acc: 0.9779 - val_mean_squared_error: 0.0019\n",
      "Epoch 76/100\n",
      "28667/28667 [==============================] - 2s 53us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9895 - val_mean_squared_error: 0.0017\n",
      "Epoch 77/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9895 - val_mean_squared_error: 0.0017\n",
      "Epoch 78/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 79/100\n",
      "28667/28667 [==============================] - 2s 57us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 80/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9860 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 81/100\n",
      "28667/28667 [==============================] - 2s 52us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9875 - val_mean_squared_error: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9899 - val_mean_squared_error: 0.0017\n",
      "Epoch 83/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 84/100\n",
      "28667/28667 [==============================] - 2s 54us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9868 - val_mean_squared_error: 0.0017\n",
      "Epoch 85/100\n",
      "28667/28667 [==============================] - 1s 48us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9897 - val_mean_squared_error: 0.0017\n",
      "Epoch 86/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9875 - val_mean_squared_error: 0.0017\n",
      "Epoch 87/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9899 - val_mean_squared_error: 0.0017\n",
      "Epoch 88/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9864 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9862 - val_mean_squared_error: 0.0017\n",
      "Epoch 89/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 90/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9858 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_acc: 0.9862 - val_mean_squared_error: 0.0017\n",
      "Epoch 91/100\n",
      "28667/28667 [==============================] - 1s 49us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9874 - val_mean_squared_error: 0.0017\n",
      "Epoch 92/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9901 - val_mean_squared_error: 0.0017\n",
      "Epoch 93/100\n",
      "28667/28667 [==============================] - 1s 50us/step - loss: 0.0018 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9907 - val_mean_squared_error: 0.0017\n",
      "Epoch 94/100\n",
      "28667/28667 [==============================] - 1s 51us/step - loss: 0.0019 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9874 - val_mean_squared_error: 0.0017\n",
      "Epoch 95/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9903 - val_mean_squared_error: 0.0017\n",
      "Epoch 96/100\n",
      "28667/28667 [==============================] - 2s 53us/step - loss: 0.0018 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9893 - val_mean_squared_error: 0.0017\n",
      "Epoch 97/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0019 - acc: 0.9862 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9895 - val_mean_squared_error: 0.0017\n",
      "Epoch 98/100\n",
      "28667/28667 [==============================] - 1s 47us/step - loss: 0.0019 - acc: 0.9863 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9899 - val_mean_squared_error: 0.0017\n",
      "Epoch 99/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0018 - acc: 0.9861 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9877 - val_mean_squared_error: 0.0017\n",
      "Epoch 100/100\n",
      "28667/28667 [==============================] - 1s 52us/step - loss: 0.0019 - acc: 0.9859 - mean_squared_error: 0.0017 - val_loss: 0.0018 - val_acc: 0.9875 - val_mean_squared_error: 0.0017\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "nb_epoch = 100\n",
    "batch_size = 32\n",
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'mse'])\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=\"autoenc_rul_model.h5\", verbose=0, save_best_only=True)\n",
    "\n",
    "history = autoencoder.fit(data, data, epochs=nb_epoch, batch_size=batch_size, shuffle=True,\n",
    "                    validation_split=0.15, verbose=1, callbacks=[checkpointer]).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "autoencoder = load_model('autoenc_rul_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.456239</td>\n",
       "      <td>0.170780</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.193367</td>\n",
       "      <td>0.422584</td>\n",
       "      <td>0.318852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976983</td>\n",
       "      <td>0.681741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.255333</td>\n",
       "      <td>0.167025</td>\n",
       "      <td>0.328936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.640435</td>\n",
       "      <td>0.675121</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.609040</td>\n",
       "      <td>0.253824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288984</td>\n",
       "      <td>0.460344</td>\n",
       "      <td>0.336474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.976860</td>\n",
       "      <td>0.664312</td>\n",
       "      <td>...</td>\n",
       "      <td>0.275191</td>\n",
       "      <td>0.153931</td>\n",
       "      <td>0.340603</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331232</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.635208</td>\n",
       "      <td>0.676429</td>\n",
       "      <td>0.000562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.258356</td>\n",
       "      <td>0.752712</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.339254</td>\n",
       "      <td>0.363063</td>\n",
       "      <td>0.307221</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.980104</td>\n",
       "      <td>0.699902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249932</td>\n",
       "      <td>0.166975</td>\n",
       "      <td>0.313690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.318009</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.656296</td>\n",
       "      <td>0.703213</td>\n",
       "      <td>0.008173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.537751</td>\n",
       "      <td>0.505763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.334019</td>\n",
       "      <td>0.237352</td>\n",
       "      <td>0.279003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984904</td>\n",
       "      <td>0.726372</td>\n",
       "      <td>...</td>\n",
       "      <td>0.235680</td>\n",
       "      <td>0.151737</td>\n",
       "      <td>0.295173</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.672543</td>\n",
       "      <td>0.713379</td>\n",
       "      <td>0.006941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.389405</td>\n",
       "      <td>0.337231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350063</td>\n",
       "      <td>0.254477</td>\n",
       "      <td>0.339593</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.975377</td>\n",
       "      <td>0.674563</td>\n",
       "      <td>...</td>\n",
       "      <td>0.258539</td>\n",
       "      <td>0.191031</td>\n",
       "      <td>0.353069</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.357442</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.612531</td>\n",
       "      <td>0.642151</td>\n",
       "      <td>0.013040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1    2    3         4         5         6    7         8   \\\n",
       "0  0.456239  0.170780  0.0  0.0  0.193367  0.422584  0.318852  0.0  0.976983   \n",
       "1  0.609040  0.253824  0.0  0.0  0.288984  0.460344  0.336474  0.0  0.976860   \n",
       "2  0.258356  0.752712  0.0  0.0  0.339254  0.363063  0.307221  0.0  0.980104   \n",
       "3  0.537751  0.505763  0.0  0.0  0.334019  0.237352  0.279003  0.0  0.984904   \n",
       "4  0.389405  0.337231  0.0  0.0  0.350063  0.254477  0.339593  0.0  0.975377   \n",
       "\n",
       "         9     ...           15        16        17   18        19   20   21  \\\n",
       "0  0.681741    ...     0.255333  0.167025  0.328936  0.0  0.328830  0.0  0.0   \n",
       "1  0.664312    ...     0.275191  0.153931  0.340603  0.0  0.331232  0.0  0.0   \n",
       "2  0.699902    ...     0.249932  0.166975  0.313690  0.0  0.318009  0.0  0.0   \n",
       "3  0.726372    ...     0.235680  0.151737  0.295173  0.0  0.300014  0.0  0.0   \n",
       "4  0.674563    ...     0.258539  0.191031  0.353069  0.0  0.357442  0.0  0.0   \n",
       "\n",
       "         22        23        24  \n",
       "0  0.640435  0.675121  0.000000  \n",
       "1  0.635208  0.676429  0.000562  \n",
       "2  0.656296  0.703213  0.008173  \n",
       "3  0.672543  0.713379  0.006941  \n",
       "4  0.612531  0.642151  0.013040  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = autoencoder.predict(data)\n",
    "feat = pd.DataFrame(predictions)\n",
    "feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Activations at the Output of Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = len(cols)\n",
    "encoding_dim = 14\n",
    "\n",
    "input_l = Input(shape=(input_dim, ))\n",
    "\n",
    "enc = Dense(encoding_dim, activation=\"tanh\", activity_regularizer=regularizers.l1(10e-5))(input_l)\n",
    "enc = Dense(int(encoding_dim / 2), activation=\"relu\")(enc)\n",
    "\n",
    "encod = Model(inputs=input_l, outputs=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "encod.set_weights(autoencoder.layers[0].get_weights())\n",
    "\n",
    "encod.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 14)                364       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 7)                 105       \n",
      "=================================================================\n",
      "Total params: 469\n",
      "Trainable params: 469\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encod.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20631/20631 [==============================] - 0s 22us/step\n",
      "13096/13096 [==============================] - 0s 15us/step\n"
     ]
    }
   ],
   "source": [
    "train_act = encod.predict(train_df[cols], verbose=1)\n",
    "test_act = encod.predict(test_df[cols], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.509679</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.198295</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.278004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.541622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.217229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.298365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.117471</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.109585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.284623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400254</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.282748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.350287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1         2    3         4    5         6\n",
       "0  0.0  0.0  0.509679  0.0  0.198295  0.0  0.278004\n",
       "1  0.0  0.0  0.541622  0.0  0.217229  0.0  0.298365\n",
       "2  0.0  0.0  0.312857  0.0  0.117471  0.0  0.109585\n",
       "3  0.0  0.0  0.481705  0.0  0.235943  0.0  0.284623\n",
       "4  0.0  0.0  0.400254  0.0  0.282748  0.0  0.350287"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_act_df = pd.DataFrame(train_act)\n",
    "test_act_df = pd.DataFrame(test_act)\n",
    "train_act_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_act_df['RUL'] = train_df['RUL']\n",
    "test_act_df['RUL'] = test_df['RUL']\n",
    "train_act_df['id'] = train_df['id']\n",
    "test_act_df['id'] = test_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = cols\n",
    "test.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['RUL'] = train_df['RUL']\n",
    "test['RUL'] = test_df['RUL']\n",
    "train['id'] = train_df['id']\n",
    "test['id'] = test_df['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    data_array = id_df[seq_cols].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_array[start:stop, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = [i for i in range(0,20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick the feature columns \n",
    "sensor_cols = ['s' + str(i) for i in range(1,22)]\n",
    "sequence_cols = ['setting1', 'setting2', 'setting3', 'cycle_norm']\n",
    "sequence_cols.extend(sensor_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_cols = [0, 1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator for the sequences\n",
    "seq_gen = (list(gen_sequence(train_act_df[train_act_df['id']==id], sequence_length, sensor_cols)) \n",
    "           for id in train_act_df['id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 50, 7)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate sequences and convert to numpy array\n",
    "seq_array = np.concatenate(list(seq_gen)).astype(np.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to generate labels\n",
    "def gen_labels(id_df, seq_length, label):\n",
    "    data_array = id_df[label].values\n",
    "    num_elements = data_array.shape[0]\n",
    "    return data_array[seq_length:num_elements, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15631, 1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_act_df[train_act_df['id']==id], sequence_length, ['RUL']) \n",
    "             for id in train_act_df['id'].unique()]\n",
    "label_array = np.concatenate(label_gen).astype(np.float32)\n",
    "label_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the network\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(\n",
    "         units=100,\n",
    "         return_sequences=True,\n",
    "         input_shape=(sequence_length, nb_features)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(units=1, activation='relu'))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.compile(loss=\"mse\", optimizer=\"rmsprop\", metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 50, 100)           43200     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 51        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 73,451\n",
      "Trainable params: 73,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictive_regression_kalhman\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "STAMP = 'predictive_regression_kalhman'\n",
    "print(STAMP)\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=10)\n",
    "bst_model_path = STAMP + '.h5'\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=RMSprop(lr=1e-2), metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14849 samples, validate on 782 samples\n",
      "Epoch 1/10\n",
      " 1000/14849 [=>............................] - ETA: 35s - loss: 5975.0957 - mean_squared_error: 5975.0957"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# fit the network\n",
    "hist = model.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.05, verbose=1,callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(bst_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15631/15631 [==============================] - 13s 808us/step\n",
      "Score: 1269.6796028210908\n"
     ]
    }
   ],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Score: {}'.format(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pd.DataFrame(np.zeros((1, 25)), columns=cols)\n",
    "test = pd.concat([test, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 50, 7)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array_test_last = [test_act_df[test_act_df['id']==id][sensor_cols].values[-sequence_length:] \n",
    "                       for id in test_act_df['id'].unique() if len(test_act_df[test_act_df['id']==id]) >= sequence_length]\n",
    "\n",
    "seq_array_test_last = np.asarray(seq_array_test_last).astype(np.float32)\n",
    "seq_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mask = [len(test_act_df[test_act_df['id']==id]) >= sequence_length for id in test_act_df['id'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93, 1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_array_test_last = test_act_df.groupby('id')['RUL'].nth(-1)[y_mask].values\n",
    "label_array_test_last = label_array_test_last.reshape(label_array_test_last.shape[0],1).astype(np.float32)\n",
    "label_array_test_last.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 50, 7)\n",
      "(93, 1)\n"
     ]
    }
   ],
   "source": [
    "print(seq_array_test_last.shape)\n",
    "print(label_array_test_last.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score: 523.89 MSE (22.89 RMSE)\n"
     ]
    }
   ],
   "source": [
    "# test metrics\n",
    "import math\n",
    "scores_test = model.evaluate(seq_array_test_last, label_array_test_last, verbose=2)\n",
    "print('Test Score: %.2f MSE (%.2f RMSE)' % (scores_test[0], math.sqrt(scores_test[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(seq_array_test_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = []\n",
    "ratio = []\n",
    "pred = model.predict(seq_array_test_last)\n",
    "for u in range(len(label_array_test_last)):\n",
    "    pr = pred[u][0]\n",
    "    ratio.append((label_array_test_last[u] / pr) - 1)\n",
    "    diff.append(abs(label_array_test_last[u] - pr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot of Predicted and True RUL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdad94e4fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt2\n",
    "\n",
    "plt2.plot(pred, color='red', label='Prediction')\n",
    "plt2.plot(label_array_test_last, color='blue', label='Ground Truth')\n",
    "plt2.legend(loc='upper left')\n",
    "plt2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>19.437393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>30.059324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-53.893448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.135217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.452305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>39.096275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>85.550095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           error\n",
       "count  93.000000\n",
       "mean   19.437393\n",
       "std    30.059324\n",
       "min   -53.893448\n",
       "25%    -1.135217\n",
       "50%    16.452305\n",
       "75%    39.096275\n",
       "max    85.550095"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = pd.DataFrame((label_array_test_last - pred),columns=['error'])\n",
    "error.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
